{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Db-mDQUqAZH3",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Versiunea CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKF72Sl006nO",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Mount Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "id": "KmDZ4OP10_M2",
    "outputId": "71ea8a9c-e32a-49d8-ff1d-64f33769ba8a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vbS5zL2W7SkZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/Master/AI\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zsTWGbjM0Eai",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ru9HLjOzKhdd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pt-JmrtbBjLP",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim.downloader as api\n",
    "import itertools\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m9KdL21FHExU",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "In00IwnB0NUa",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Choose dataset, embedding method and algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "vzud9mbK0V2t",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#@title Dataset\n",
    "\n",
    "dataset_name = 'Hateval2019' #@param [\"Hateval2019\", \"Davidson\"] {allow-input: true}\n",
    "\n",
    "print(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "w6_gVTDI2UEi",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#@title Embedding Method\n",
    "\n",
    "embedding_method_name = 'ELMo' #@param [\"ELMo\", \"FastText\", \"Word2Vec\", \"GloVe\", \"BERT\"] {allow-input: true}\n",
    "\n",
    "print(embedding_method_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_4uZH8RJqa6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SRVHAiw4DDEY",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_hateval2019_dataset(file_path: str):\n",
    "    \"\"\"\n",
    "    Loads the Hateval2019 dataset from a CSV file located at the specified file path\n",
    "    and returns a Pandas DataFrame containing the loaded data.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the CSV file containing the Hateval2019 dataset.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A Pandas DataFrame containing the loaded data.\n",
    "    \"\"\"\n",
    "    column_names = [\"id\", \"text\", \"HS\", \"TR\", \"AG\"]\n",
    "    df = pd.read_csv(file_path, names=column_names, header=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O6MulXReJuQx",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# def load_davidson_dataset(file_path: str):\n",
    "#     \"\"\"\n",
    "#     Loads the Davidson dataset from a CSV file located at the specified file path\n",
    "#     and returns a Pandas DataFrame containing the loaded data.\n",
    "\n",
    "#     Args:\n",
    "#         file_path (str): The path to the CSV file containing the Davidson dataset.\n",
    "\n",
    "#     Returns:\n",
    "#         pd.DataFrame: A Pandas DataFrame containing the loaded data.\n",
    "#     \"\"\"\n",
    "#     column_names = [\"count\", \"hate_speech\", \"offensive_language\", \"neither\", \"class\", \"tweet\"]\n",
    "#     df = pd.read_csv(file_path, names=column_names, header=0)\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FKJQBpHS1x1M",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load Hateval2019 dataset and print execution time\n",
    "start = time.time()\n",
    "hateval2019_dataset = load_hateval2019_dataset(\"/content/drive/MyDrive/Master/AI/DATASETS/HATEVAL/hateval2019_en.csv\")\n",
    "end = time.time()\n",
    "print(f\"Execution time: {end-start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-B4WgkSPJapH",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # Load Davidson dataset and print execution time\n",
    "# start = time.time()\n",
    "# davidson_dataset = load_davidson_dataset(\"/content/drive/MyDrive/Master/AI/DATASETS/TWITTER/labeled_data.csv\")\n",
    "# end = time.time()\n",
    "# print(f\"Execution time: {end-start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y9BZnIeaLbK0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if dataset_name == 'Hateval2019':\n",
    "  data = hateval2019_dataset['text']\n",
    "  labels = hateval2019_dataset['HS']\n",
    "# elif dataset_name == 'Davidson':\n",
    "#   data = davidson_dataset['tweet']\n",
    "#   labels = davidson_dataset['hate_speech']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2akTT40oHZpu",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ebT0qzy5Hb9U",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocesses text data by performing the following steps:\n",
    "    - Removes HTML tags and URLs\n",
    "    - Tokenizes the text\n",
    "    - Converts tokens to lowercase\n",
    "    - Removes stopwords\n",
    "    - Lemmatizes tokens\n",
    "\n",
    "    Args:\n",
    "        text (str): The text data to preprocess\n",
    "\n",
    "    Returns:\n",
    "        str: A preprocessed string\n",
    "    \"\"\"\n",
    "    # Remove HTML tags and URLs\n",
    "    text = re.sub('<[^<]+?>', '', text)\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Convert to lowercase\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # Lemmatize the tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    # Join the preprocessed tokens back into a string\n",
    "    preprocessed_text = \" \".join(tokens)\n",
    "\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d5z3dW5MHh1l",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = data.apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HS3b-WkwGO1O",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ChetXmsEIyJ7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_glove_model(file_path):\n",
    "    \"\"\"\n",
    "    Loads the GloVe model from a file located at the specified file path and \n",
    "    returns a dictionary containing the word vectors from the model.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the file containing the GloVe model.\n",
    "\n",
    "    Returns:\n",
    "        dict: A Python dictionary object containing the word vectors from the \n",
    "        GloVe model. Each key in the dictionary represents a word, and the value \n",
    "        associated with the key is a numpy array that contains the corresponding \n",
    "        word vector.\n",
    "    \"\"\"\n",
    "    glove_model = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            glove_model[word] = vector\n",
    "    return glove_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0taO9E50I9tB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def elmo_vectors(text, batch_size=8):\n",
    "    \"\"\"\n",
    "    Computes ELMo embeddings for the given text using a pre-trained ELMo model.\n",
    "\n",
    "    Args:\n",
    "        text (numpy.ndarray): A 1-dimensional numpy array containing the text for \n",
    "        which ELMo embeddings are to be computed.\n",
    "        batch_size (int, optional): The batch size to use when computing embeddings. \n",
    "        Defaults to 8.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: A 2-dimensional numpy array containing the ELMo embeddings \n",
    "        for the given text. Each row in the array represents a sentence, and each \n",
    "        column represents a dimension in the embedding space.\n",
    "    \"\"\"\n",
    "    num_batches = len(text) // batch_size + (1 if len(text) % batch_size > 0 else 0)\n",
    "    embeddings = []\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        start_index = i * batch_size\n",
    "        end_index = min((i + 1) * batch_size, len(text))\n",
    "        batch_text = text[start_index:end_index]\n",
    "        batch_embeddings = elmo(tf.convert_to_tensor(batch_text.tolist()), training=False)\n",
    "        embeddings.append(batch_embeddings.numpy())\n",
    "\n",
    "    return np.concatenate(embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "igoQQ_c-JFmI",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fasttext_word2vec_vectors(text, model):\n",
    "    \"\"\"\n",
    "    Computes FastText word embeddings for the given text using a pre-trained \n",
    "    FastText model.\n",
    "\n",
    "    Args:\n",
    "        text (list): A list of strings containing the text for which FastText \n",
    "        embeddings are to be computed.\n",
    "        model (fasttext.FastText._FastText): The pre-trained FastText model to \n",
    "        use for computing embeddings.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: A 2-dimensional numpy array containing the FastText \n",
    "        embeddings for the given text. Each row in the array represents a \n",
    "        sentence, and each column represents a dimension in the embedding space.\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    zero_vector = np.zeros(model.vector_size)\n",
    "\n",
    "    for sentence in text:\n",
    "        words = sentence.split()\n",
    "        sentence_embeddings = [model[word] for word in words if word in model]\n",
    "        \n",
    "        if not sentence_embeddings:\n",
    "            sentence_embeddings = [zero_vector]\n",
    "        \n",
    "        embeddings.append(np.mean(sentence_embeddings, axis=0))\n",
    "\n",
    "    return np.array(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_TSZcVj-JMKD",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def glove_vectors(text):\n",
    "    \"\"\"\n",
    "    Computes GloVe embeddings for the given text using a pre-loaded GloVe model.\n",
    "\n",
    "    Args:\n",
    "        text (list): A list of strings containing the text for which GloVe \n",
    "        embeddings are to be computed.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: A 2-dimensional numpy array containing the GloVe embeddings \n",
    "        for the given text. Each row in the array represents a sentence, and each \n",
    "        column represents a dimension in the embedding space.\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    \n",
    "    # Get the vector size from the first word in the dictionary\n",
    "    vector_size = len(next(iter(glove_model.values())))\n",
    "    zero_vector = np.zeros(vector_size)\n",
    "\n",
    "    for sentence in text:\n",
    "        words = sentence.split()\n",
    "        sentence_embeddings = [glove_model[word] for word in words if word in glove_model]\n",
    "\n",
    "        if not sentence_embeddings:\n",
    "            sentence_embeddings = [zero_vector]\n",
    "\n",
    "        embeddings.append(np.mean(sentence_embeddings, axis=0))\n",
    "\n",
    "    return np.array(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mbrOn3kVJTi_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def bert_vectors(text, batch_size=32):\n",
    "    \"\"\"\n",
    "    Computes BERT embeddings for the given text using a pre-trained BERT model.\n",
    "\n",
    "    Args:\n",
    "        text (list): A list of strings containing the text for which BERT embeddings \n",
    "        are to be computed.\n",
    "        batch_size (int, optional): The batch size to use when computing embeddings. \n",
    "        Defaults to 32.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: A 2-dimensional numpy array containing the BERT embeddings \n",
    "        for the given text. Each row in the array represents a sentence, and each \n",
    "        column represents a dimension in the embedding space.\n",
    "    \"\"\"\n",
    "    # Load the BERT tokenizer and model\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "    # Compute the number of batches\n",
    "    num_batches = len(text) // batch_size + (1 if len(text) % batch_size > 0 else 0)\n",
    "    embeddings = []\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        start_index = i * batch_size\n",
    "        end_index = min((i + 1) * batch_size, len(text))\n",
    "        batch_text = text[start_index:end_index]\n",
    "\n",
    "        # Tokenize the batch of text and generate input tensors for the model\n",
    "        inputs = tokenizer(batch_text.tolist(), return_tensors=\"tf\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "        # Generate embeddings for the batch using the BERT model\n",
    "        outputs = model(inputs)\n",
    "        batch_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "        embeddings.append(batch_embeddings.numpy())\n",
    "\n",
    "    return np.concatenate(embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s6WWqDmKGi_M",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if embedding_method_name == \"ELMo\":\n",
    "  elmo = hub.KerasLayer(\"https://tfhub.dev/google/elmo/3\", trainable=False)\n",
    "  embeddings_func = elmo_vectors\n",
    "elif embedding_method_name == \"FastText\":\n",
    "  fasttext_model = api.load(\"fasttext-wiki-news-subwords-300\")\n",
    "  embeddings_func = lambda text: fasttext_word2vec_vectors(text, fasttext_model)\n",
    "elif embedding_method_name == \"Word2Vec\":\n",
    "  word2vec_model = api.load(\"word2vec-google-news-300\")\n",
    "  embeddings_func = lambda text: fasttext_word2vec_vectors(text, word2vec_model)\n",
    "elif embedding_method_name == \"GloVe\":\n",
    "  glove_model = load_glove_model('/content/drive/MyDrive/Master/AI/glove.6B.50d.txt')\n",
    "  embeddings_func = glove_vectors\n",
    "elif embedding_method_name == \"BERT\":\n",
    "  bert = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\", trainable=False)\n",
    "  embeddings_func = bert_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y0jhU7iULZwJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "embeddings = embeddings_func(data)\n",
    "print(f\"{embedding_method_name} embeddings shape:\", embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ve66B7JbCmPp",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LHraf-inK4l3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = embeddings\n",
    "y = labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lzUJI5jkCqSo",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ht2nIoJIDa74",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O_jQWLo6BYSI",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print(f\"Execution time: {end-start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BB9uCs5xBbFg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "gnb_accuracy = gnb.score(X_test, y_test)\n",
    "end = time.time()\n",
    "print(f\"Execution time: {end-start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5iwlWMgDeVK",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aMbEVyrVNW73",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print(f\"Execution time: {end-start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ob95z1qn59qI",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "bnb_accuracy = bnb.score(X_test, y_test)\n",
    "end = time.time()\n",
    "print(f\"Execution time: {end-start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ClaadbrLDizR",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SlExDPKyOfkr",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print(f\"Execution time: {end-start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GS0pAWas6LCn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "lr_accuracy = lr.score(X_test, y_test)\n",
    "end = time.time()\n",
    "print(f\"Execution time: {end-start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LzB1XADLDl45",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n0cp964QOhqa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print(f\"Execution time: {end-start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "obMoU6Ze6Wmf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "svm_accuracy = svm.score(X_test, y_test)\n",
    "end = time.time()\n",
    "print(f\"Execution time: {end-start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlErclm8Mz7S",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eRdY8x4oM4YX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=5)\n",
    "rf.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print(f\"Execution time: {end-start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6kIN6flNL6A",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "rf_accuracy = rf.score(X_test, y_test)\n",
    "end = time.time()\n",
    "print(f\"Execution time: {end-start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1s7711KDpKu",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IZVECJAbOnXD",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Gaussian Naive Bayes Train Accuracy: {gnb.score(X_train, y_train) * 100:.2f}\")\n",
    "print(f\"Bernoulli Naive Bayes Train Accuracy: {bnb.score(X_train, y_train) * 100:.2f}\")\n",
    "print(f\"Logistic Regression Train Accuracy: {lr.score(X_train, y_train) * 100:.2f}\")\n",
    "print(f\"SVM Train Accuracy: {svm.score(X_train, y_train) * 100:.2f}\")\n",
    "print(f\"Random Train Forest Accuracy: {rf.score(X_train, y_train) * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PVLCTg3rR0Si",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Gaussian Naive Bayes Test Accuracy: {gnb_accuracy * 100:.2f}\")\n",
    "print(f\"Bernoulli Naive Bayes Test Accuracy: {bnb_accuracy * 100:.2f}\")\n",
    "print(f\"Logistic Regression Test Accuracy: {lr_accuracy * 100:.2f}\")\n",
    "print(f\"SVM Test Accuracy: {svm_accuracy * 100:.2f}\")\n",
    "print(f\"Random Test Forest Accuracy: {rf_accuracy * 100:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}